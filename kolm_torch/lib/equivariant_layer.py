import torch
import torch.nn as nn


class SymmetryFactory():
    '''
    This class just provides functions for augmenting data via symmetry operations.
    We can use this to check if a network is actually equivariant
    '''

    def __init__(self):
        super().__init__()

    def rot90(self, tensor):
        '''
        PURPOSE:
        This applies a 90 degree rotation to a tensor of size [b,c,n,n].
        Because of the way points are stored, we will need to circularly pad before
        '''

        #define a function for padding to the right and below
        extend = nn.CircularPad2d((0,1,0,1))
        n = tensor.shape[2]

        #pad
        tensor = extend(tensor)
        
        #rotate
        tensor = torch.rot90( tensor, k=1, dims=(2,3) )
        
        #unpad
        tensor = tensor[:,:,:n,:n]
        return tensor


class EquivariantLayer(nn.Module):
    def __init__(self, c1, c2, n1, n2):
        '''
        The goal of this network is to map a [b,n1,n1,c1] tensor to a [b,n2,n2,c2]
        b - batch
        c1- input channels
        c2- output channels
        n1- input grid resolution
        n2- output grid resolution 
        '''

        super().__init__()
        
        #The kernel for convolutions only needs to be this size
        n_min = min( (n1,n2) ) 
        n_max = max( (n1,n2) )

        #Only two trainable paramaters: the trainable
        self.kernel = torch.nn.Parameter(  torch.randn(1, n_min, n_min, c1, c2))
        self.bias   = torch.nn.Parameter(  torch.randn(1,     1,     1, c2))
        #self.linear = nn.Linear( c1, c2 ) #The linear operator acts on the channels

        self.c1 = c1
        self.c2 = c2
        self.n1 = n1
        self.n2 = n2
        
        #construct two masks for changing grid resolution
        #we need two because of the way the real fft (rfft) stores output
        k = torch.arange(n_max)
        k[k>n_max//2] = k[k>n_max//2] - n_max
        self.mask  = torch.abs(k) <= n_min/2
        self.mask2 = self.mask[0:(n_max//2+1)]
        self.mask[k==-n_min/2] = False #Make sure there is only one nyquist frequency

        #I also want to store an array for going from a vorticity to its generating vector field
        k       = torch.arange(n2)
        k_small = torch.arange(n2//2+1)
        k[k>n2//2] = k[k>n2//2] - n2

        kx = torch.reshape( k,       [-1,1])        
        ky = torch.reshape( k_small, [1,-1])
        
        to_u =  1j*ky/(kx*kx + ky*ky)
        to_v = -1j*kx/(kx*kx + ky*ky)
        to_u[0,0] = 0
        to_v[0,0] = 0
        
        #add batch and channel dimensions
        self.to_u = torch.unsqueeze(torch.unsqueeze(to_u,2),0)
        self.to_v = torch.unsqueeze(torch.unsqueeze(to_v,2),0)

        #create a third mask for unique antisymmetric combinations for cross products
        idx1   = torch.unsqueeze( torch.arange(c2), 0 )
        idx2   = torch.unsqueeze( torch.arange(c2), 1 )
        self.mask3 = torch.reshape( idx1-idx2 > 0, [-1] )


    def symmetric_kernel(self):
        '''
        Symmetrize the kernel with respect to D4, the symmetry group of a square
        I'm usin gthe fact that D4 is generated by a reflection about the diagonal and 90 degree rotations
        '''

        k1 = self.kernel
        k2 = torch.transpose(k1,1,2) #flipped along diagonal
        
        k3 = torch.rot90( k1, k=1, dims=(1,2) )
        k4 = torch.rot90( k1, k=2, dims=(1,2) )
        k5 = torch.rot90( k1, k=3, dims=(1,2) )
        
        k6 = torch.rot90( k2, k=1, dims=(1,2) )
        k7 = torch.rot90( k2, k=2, dims=(1,2) )
        k8 = torch.rot90( k2, k=3, dims=(1,2) )

        k = (k1 + k2 + k3 + k4 + k5 + k6 + k7 + k8)/8
        return k
    

    def forward(self, f ):
        #k = self.symmetric_kernel()
        k = self.kernel

        #Change f and k to Fourier space
        f = torch.fft.rfft2( f, dim=[1,2]) #default
        k = torch.fft.rfft2( k, dim=[1,2]) #default

        #Do downsampling if needed
        if self.n2 < self.n1:
            #Torch wants me to do the logical indexing one axis at a time
            f = f[:,        :,self.mask2,:]
            f = f[:,self.mask,         :,:]

        #Convolve == multiply in Fourier space
        f = torch.unsqueeze(f,4)
        f = f*k
        f = torch.sum(f, dim=3)

        #Do upsampling if needed
        if self.n2 > self.n1:
            b = f.shape[0]
            c = f.shape[3]

            #Torch hates multiple row Boolean indexing, so I have to do this insane work-around

            temp = f
            f = torch.zeros( (b,self.n1,self.n2//2+1,c), dtype=torch.complex64 )
            f[:,:,self.mask2,:] = temp

            temp = f
            f = torch.zeros( (b,self.n2,self.n2//2+1,c), dtype=torch.complex64 )
            f[:,self.mask,:,:] = temp

        #print(f.shape)
        #print(self.to_u.shape)

        #Now we have a [b,n2,n2,c2] object
        #construct the fluid components of these vorticity fields by uncurling
        u = self.to_u * f
        v = self.to_v * f
        u = torch.fft.irfft2(u,dim=[1,2])
        v = torch.fft.irfft2(v,dim=[1,2])

        #compute the cross product of u and v
        u = torch.unsqueeze(u,4)
        v = torch.unsqueeze(v,3)
        cross = u*v-v*u

        #combine last two indices
        cross = cross.reshape( cross.shape[:-2] + (-1,))
        #cross = torch.reshape( cross, [-1,self.n2,self.n2,self.c2*self.c2] )
        
        #restrict to unique combinations
        f = cross[:,:,:,self.mask3]


        #transform back to real space
        #f = torch.fft.irfft2(f,dim=[1,2])
        
        return f


class EquivariantDenseBlock(nn.Module):
    '''
    Inspired by "Densely Connected Convolutional Networks" by Huang et al.
    '''
    def __init__(self, n1, n2, c1, c2, num_layers, activation ):
        '''
        The goal of this block is to apply exactly translational equivariant convolutions, 
        but in the style of a "DenseBlock" in the sense of Huang.

        INPUT:
        nl - number of layers. 
        activation - activation function
        '''
        super().__init__()

        self.activation = activation

        layers = []
        num_features = c1 #this will change
        for i in range(num_layers-1):
            layers.append( EquivariantLayer(num_features, c2, n1, n1) )
            num_features = num_features + c2 #since we concat input with output

        #At the last layer, change resolution
        layers.append( EquivariantLayer(num_features, c2, n1, n2) )
        self.layers = layers

    def forward(self, x):
        for layer in self.layers:
            output = self.activation(layer(x))
            x = torch.cat( (x,output), dim=3 )
        return x

class EquivariantAutoencoder(nn.Module):
    def __init__(self):
        super().__init__()

        c      = 4 #intermediate channels
        c2     = (c*(c-1))//2
        c_enc  = 2 #channels of the encoder
        c2_enc = (c_enc*(c_enc-1))//2
        
        #encoding layers
        self.elayer1 = EquivariantLayer(c1=2,  c2=c,     n1=64, n2=32) # take in vorticity and force, so c1=2
        self.elayer2 = EquivariantLayer(c1=c2, c2=c,     n1=32, n2=16)
        self.elayer3 = EquivariantLayer(c1=c2, c2=c_enc, n1=16, n2=8)
        
        #decoding layers
        self.dlayer1 = EquivariantLayer(c1=c2_enc, c2=c, n1= 8, n2=16)
        self.dlayer2 = EquivariantLayer(c1=c2,     c2=c, n1=16, n2=32) 
        self.dlayer3 = EquivariantLayer(c1=c2,     c2=c, n1=32, n2=64) 
        self.final_layer = nn.Linear(c2,1,bias=False)

        sig = nn.Sigmoid()
        self.activation = lambda x: x
        #self.activation = lambda x: 2*sig(x) - 1

    def encode(self, f):
        f = self.activation(self.elayer1(f))
        f = self.activation(self.elayer2(f))
        f = self.activation(self.elayer3(f))
 
        return f
    
    def decode(self, f):
        
        f = self.activation(self.dlayer1(f))
        f = self.activation(self.dlayer2(f))
        f = self.activation(self.dlayer3(f))
        f = self.final_layer(f)
        
        return f
        

if __name__ == "__main__":
    #Do some quick testing
    n1 = 64
    c1 = 2  #w and forcing
    b  = 24 #batch size

    n2 = 32 #try upsampling and downsampling
    c2 = 7


    w = torch.randn(b, n1, n1, c1)

    eq = EquivariantLayer(c1, c2, n1, n2)
    w2 = eq.forward(w)

    enc = EquivariantAutoencoder()

    l = enc.encode(w)
    print( l.shape )

    w3 = enc.decode(l)
    print( w3.shape )